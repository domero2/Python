import osimport pandas as pdfrom pandas import isnullBASE_PATH = os.path.dirname(os.path.abspath(__file__))master = pd.read_csv(os.path.join(BASE_PATH,'input','Master.csv'))master5=master.head(5)(master.shape) # (8670, 31) shape return count of the rows(master.columns)#Index(['playerID', 'coachID', 'hofID', 'firstName', 'lastName', 'nameNote',       #'nameGiven', 'nameNick', 'height', 'weight', 'shootCatch', 'legendsID',       #'ihdbID', 'hrefID', 'firstNHL', 'lastNHL', 'firstWHA', 'lastWHA', 'pos',       #'birthYear', 'birthMon', 'birthDay', 'birthCountry', 'birthState',       #'birthCity', 'deathYear', 'deathMon', 'deathDay', 'deathCountry',       #'deathState', 'deathCity'],      #dtype='object')(master["playerID"].pipe(isnull).value_counts())(isnull(master["playerID"]).value_counts())#False    8407 True      263 Name: playerID, dtype: int64#getting rid off records where PlayerId is nullclear_master = master.dropna(subset=["playerID"])clear_master = clear_master.dropna(subset=['firstNHL','lastNHL'],how='all')clear_master = clear_master.loc[clear_master["lastNHL"]>=1980]#get only needed columns, defining list of columns and using regex#clear_master_quicker = clear_master.filter(regex="playerId|pos|^birth|Name$")usefull_columns = ['playerID', 'firstName', 'lastName','pos','birthYear', 'birthMon',                   'birthDay', 'birthCountry', 'birthState','birthCity']clear_master = clear_master.filter(usefull_columns)#Comparison of memory usage by two data set initial:2.05 MB, cleared:0.4 6MB def memoryUsage(input_variable):    print("{0:.2f} MB".format(        input_variable.memory_usage().sum()/(1024*1024)))#memoryUsage(clear_master)#memoryUsage(master)#to speed up pandas we could categorical in columns similar to creating index(clear_master["pos"].value_counts())(pd.Categorical(clear_master["pos"]))#Check which columns we could categorize and choose those which has the least amount(clear_master.nunique())def categorizeColumns(input_data_frame, column_name):    input_data_frame.loc[:, column_name] = pd.Categorical(input_data_frame[column_name])    categorizeColumns(clear_master, "pos")categorizeColumns(clear_master, "birthCountry") categorizeColumns(clear_master, "birthState")# memory usage after categorization: 0.36 MB#memoryUsage(clear_master)    #seting index of data frame for playerID as unique columnclear_master = clear_master.set_index("playerID")clear_master.to_csv(os.path.join(BASE_PATH,'output','Cleared_master.csv'))##########Clearing Scoring data############scoring = pd.read_csv(os.path.join(BASE_PATH,'input','Scoring.csv'))#Inital size is 12.36 MB#memoryUsage(scoring)(scoring.columns)#Get only data for NHL league and after 1980 yeardef clearInitalData(first_col,first_col_val, sec_col, sec_col_val, dataframe):    return dataframe[(dataframe[first_col]==first_col_val) \                     & (dataframe[sec_col]>=sec_col_val)]scoring = clearInitalData("lgID","NHL","year",1980,scoring)#Removed each columns which starts from Post or PP or SHscoring_fitered = scoring.filter(regex="^(?!(Post|PP|SH)).*")(scoring_fitered.columns)#Index(['playerID', 'year', 'stint', 'tmID', 'lgID', 'pos', 'GP', 'G', 'A',#       'Pts', 'PIM', '+/-', 'GWG', 'GTG', 'SOG'],#      dtype='object')# select only chossen index of columns, but all rowsscoring_fitered = scoring_fitered.iloc[:, [0,1,3,6,7,8,9,14]]#Define some categorical columnscategorizeColumns(scoring_fitered, "tmID")#Reseting index to start from 0 and increment by one, because after filtering order is upsetscoring_fitered.reset_index().head()#Scoring data after optimization : 8.52MB#memoryUsage(scoring)scoring_fitered.to_csv(os.path.join(BASE_PATH,'output','Cleared_scoring.csv'))#######Clearing Teams##################teams = pd.read_csv(os.path.join(BASE_PATH,'input','Teams.csv'))teams = clearInitalData("lgID","NHL","year",1980,teams)teams = teams [["year","tmID","name"]]#Categorize tmIDcategorizeColumns(teams, "tmID")teams.to_csv(os.path.join(BASE_PATH,'output','Cleared_teams.csv'))#######Clearing Teams Splits###########team_splits = pd.read_csv(os.path.join(BASE_PATH,'input','TeamSplits.csv'))drop_columns = team_splits.columns[3:11]team_splits= team_splits.drop(columns=drop_columns)team_splits= team_splits.drop(columns="lgID")categorizeColumns(team_splits, "tmID")team_splits.to_csv(os.path.join(BASE_PATH,'output','Cleared_teams_splits.csv'))