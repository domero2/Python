import osimport pandas as pdfrom pandas import isnullBASE_PATH = os.path.dirname(os.path.abspath(__file__))master = pd.read_csv(os.path.join(BASE_PATH,'input','Master.csv'))master5=master.head()(master.shape) # (8670, 31) shape return count of the rows(master.columns)#Index(['playerID', 'coachID', 'hofID', 'firstName', 'lastName', 'nameNote',       #'nameGiven', 'nameNick', 'height', 'weight', 'shootCatch', 'legendsID',       #'ihdbID', 'hrefID', 'firstNHL', 'lastNHL', 'firstWHA', 'lastWHA', 'pos',       #'birthYear', 'birthMon', 'birthDay', 'birthCountry', 'birthState',       #'birthCity', 'deathYear', 'deathMon', 'deathDay', 'deathCountry',       #'deathState', 'deathCity'],      #dtype='object')(master["playerID"].pipe(isnull).value_counts())(isnull(master["playerID"]).value_counts())#False    8407 True      263 Name: playerID, dtype: int64#getting rid off records where PlayerId is nullclear_master = master.dropna(subset=["playerID"])clear_master = clear_master.dropna(subset=['firstNHL','lastNHL'],how='all')clear_master = clear_master.loc[clear_master["lastNHL"]>=1980]#get only needed columns, defining list of columns and using regex#clear_master_quicker = clear_master.filter(regex="playerId|pos|^birth|Name$")usefull_columns = ['playerID', 'firstName', 'lastName','pos','birthYear', 'birthMon',                   'birthDay', 'birthCountry', 'birthState','birthCity']clear_master = clear_master.filter(usefull_columns)#Comparison of memory usage by two data set initial:2.05 MB, cleared:0.4 6MB def memoryUsage(input_variable):    print("{0:.2f} MB".format(        input_variable.memory_usage().sum()/(1024*1024)))#memoryUsage(clear_master)#memoryUsage(master)#to speed up pandas we could categorical in columns similar to creating index(clear_master["pos"].value_counts())(pd.Categorical(clear_master["pos"]))def categorizeColumns(input_data_frame, column_name):    input_data_frame.loc[:, column_name] = pd.Categorical(input_data_frame[column_name])    categorizeColumns(clear_master, "pos")categorizeColumns(clear_master, "birthCountry") categorizeColumns(clear_master, "birthState")# memory usage after categorization: 0.36 MB#memoryUsage(clear_master)    #seting undesx of data frame for playerID as unique columnclear_master = clear_master.set_index("playerID")clear_master.head()clear_master.to_csv(os.path.join(BASE_PATH,'output','Cleared_master.csv'))#Clearing Scoring datascoring = pd.read_csv(os.path.join(BASE_PATH,'input','Scoring.csv'))#Inital size is 12.36 MB#memoryUsage(scoring)(scoring.columns)#Get only data for NHL league and after 1980 yeardef clearInitalData(first_col,first_col_val, sec_col, sec_col_val, dataframe):    return dataframe[(dataframe[first_col]==first_col_val) \                     & (dataframe[sec_col]==sec_col_val)]scoring = clearInitalData("lgID","NHL","year",1980,scoring)#Scoring data after optimization : 0.17MBmemoryUsage(scoring)# JOINING COLUMNS#default join will be inner#pd.merge(dataframe1, dataframe2, left_on='playerId', right_on='plrId', how='left')